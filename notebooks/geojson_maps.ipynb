{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3d9a987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies if missing (uncomment as needed)\n",
    "# !pip install geopandas folium pandas fiona shapely pyproj\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster, FastMarkerCluster\n",
    "import math\n",
    "\n",
    "BASE = Path('NY Crimes')  # base data directory\n",
    "PSA_FILE = BASE / 'NYCHA PSA (Police Service Areas).geojson'\n",
    "SECTORS_FILE = BASE / 'NYPD Sectors.geojson'\n",
    "PRECINCTS_FILE = BASE / 'Police Precincts.geojson'\n",
    "COMPLAINTS_2019_CSV = BASE / 'NYPD_Complaint_Data_Historic_2019.csv'  # fallback CSV\n",
    "GDB_PATH = BASE / 'ny_data.gdb'  # optional feature class source\n",
    "FEATURECLASS_NAME = 'NYPD_Complaint_Data_Historic_2019_4326'  # expected point layer name\n",
    "\n",
    "# Central coordinates (NYC approximate)\n",
    "NYC_LAT, NYC_LON = 40.7128, -74.0060\n",
    "\n",
    "# Performance knobs\n",
    "MAX_POINTS = 10000  # limit point markers to avoid huge HTML\n",
    "\n",
    "print('Data directory exists:', BASE.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b981dd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded.\n"
     ]
    }
   ],
   "source": [
    "# Helper utilities\n",
    "def simplify_geometries(gdf: gpd.GeoDataFrame, tolerance: float = 0.001) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Return copy with simplified geometries (project to EPSG:3857 for metric simplification).\"\"\"\n",
    "    if gdf.crs is None:\n",
    "        return gdf\n",
    "    try:\n",
    "        projected = gdf.to_crs(3857)\n",
    "        simplified_geom = projected.geometry.simplify(tolerance, preserve_topology=True)\n",
    "        out = projected.copy()\n",
    "        out.geometry = simplified_geom\n",
    "        return out.to_crs(4326)\n",
    "    except Exception as e:\n",
    "        print('Simplification failed:', e)\n",
    "        return gdf\n",
    "\n",
    "def safe_read_gdb(gdb_path: Path, layer: str):\n",
    "    try:\n",
    "        return gpd.read_file(gdb_path, layer=layer)\n",
    "    except Exception as e:\n",
    "        print(f'GDB read failed ({layer}):', e)\n",
    "        return None\n",
    "\n",
    "def detect_coordinate_columns(df: pd.DataFrame):\n",
    "    cands_lat = [c for c in df.columns if c.lower() in ('latitude','lat','y')]\n",
    "    cands_lon = [c for c in df.columns if c.lower() in ('longitude','lon','lng','x')]\n",
    "    return (cands_lat[0] if cands_lat else None, cands_lon[0] if cands_lon else None)\n",
    "\n",
    "def try_build_points(df: pd.DataFrame, lat_col: str, lon_col: str):\n",
    "    subset = df[[lat_col, lon_col]].dropna()\n",
    "    # basic validity filter for NYC bounding box\n",
    "    subset = subset[(subset[lat_col].between(40.3, 41.0)) & (subset[lon_col].between(-74.5, -73.5))]\n",
    "    gdf = gpd.GeoDataFrame(subset, geometry=gpd.points_from_xy(subset[lon_col], subset[lat_col]), crs='EPSG:4326')\n",
    "    return gdf\n",
    "\n",
    "def sanitize_properties(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Cast non-JSON-serializable types (e.g., pandas Timestamps) to strings.\n",
    "    Handles timezone-aware datetimes by converting to UTC then dropping tz.\n",
    "    \"\"\"\n",
    "    out = gdf.copy()\n",
    "    for col in out.columns:\n",
    "        if col == 'geometry':\n",
    "            continue\n",
    "        ser = out[col]\n",
    "        # Datetime-like columns\n",
    "        if pd.api.types.is_datetime64_any_dtype(ser) or pd.api.types.is_timedelta64_dtype(ser):\n",
    "            try:\n",
    "                # If timezone-aware, convert to UTC then naive\n",
    "                if hasattr(ser.dtype, 'tz') and ser.dtype.tz is not None:\n",
    "                    ser = ser.dt.tz_convert('UTC').dt.tz_localize(None)\n",
    "                else:\n",
    "                    # ensure ns precision\n",
    "                    ser = ser.astype('datetime64[ns]')\n",
    "                out[col] = ser.dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            except Exception as e:\n",
    "                # fallback to string\n",
    "                out[col] = ser.astype(str)\n",
    "        else:\n",
    "            # Convert pandas Timestamp objects inside object dtype\n",
    "            if ser.dtype == 'object':\n",
    "                def _convert(v):\n",
    "                    try:\n",
    "                        if hasattr(v, 'isoformat'):\n",
    "                            # If tz-aware Timestamp\n",
    "                            if isinstance(v, pd.Timestamp) and v.tz is not None:\n",
    "                                return v.tz_convert('UTC').tz_localize(None).isoformat()\n",
    "                            return v.isoformat()\n",
    "                        if isinstance(v, pd.Timestamp):\n",
    "                            return v.isoformat()\n",
    "                        return v\n",
    "                    except Exception:\n",
    "                        return str(v)\n",
    "                out[col] = ser.apply(_convert)\n",
    "    return out\n",
    "\n",
    "print('Helper functions loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce4412ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer counts: 16 302 77\n",
      "Simplification complete.\n",
      "Simplification complete.\n"
     ]
    }
   ],
   "source": [
    "# Load boundary GeoJSON layers\n",
    "psa = gpd.read_file(PSA_FILE)\n",
    "sectors = gpd.read_file(SECTORS_FILE)\n",
    "precincts = gpd.read_file(PRECINCTS_FILE)\n",
    "\n",
    "# Normalize CRS to WGS84 (Leaflet expects EPSG:4326)\n",
    "for name, gdf in [('PSA', psa), ('Sectors', sectors), ('Precincts', precincts)]:\n",
    "    if gdf.crs and gdf.crs.to_epsg() != 4326:\n",
    "        print(f'Reprojecting {name} from {gdf.crs} to EPSG:4326')\n",
    "        gdf.to_crs(4326, inplace=True)\n",
    "\n",
    "print('Layer counts:', len(psa), len(sectors), len(precincts))\n",
    "# Increase simplification tolerance to shrink HTML size (meters via 3857 projection inside helper)\n",
    "psa_simplified = simplify_geometries(psa, 50)\n",
    "sectors_simplified = simplify_geometries(sectors, 25)\n",
    "precincts_simplified = simplify_geometries(precincts, 100)\n",
    "print('Simplification complete.')\n",
    "\n",
    "# Sanitize properties to avoid Folium JSON serialization issues\n",
    "psa_simplified = sanitize_properties(psa_simplified)\n",
    "sectors_simplified = sanitize_properties(sectors_simplified)\n",
    "precincts_simplified = sanitize_properties(precincts_simplified)\n",
    "\n",
    "# Prune non-essential columns to reduce HTML payload\n",
    "\n",
    "def keep_minimal_columns(gdf, keys):\n",
    "    cols = ['geometry']\n",
    "    for k in keys:\n",
    "        cols.extend([c for c in gdf.columns if c != 'geometry' and k in c.lower()])\n",
    "    # de-duplicate, preserve order\n",
    "    cols = list(dict.fromkeys(cols))\n",
    "    # Always keep at least geometry\n",
    "    cols = [c for c in cols if c in gdf.columns]\n",
    "    return gdf[cols]\n",
    "\n",
    "psa_simplified = keep_minimal_columns(psa_simplified, ['psa', 'name', 'id', 'label'])\n",
    "sectors_simplified = keep_minimal_columns(sectors_simplified, ['sector', 'sect', 'name', 'id', 'label'])\n",
    "precincts_simplified = keep_minimal_columns(precincts_simplified, ['precinct', 'prec', 'name', 'id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca360cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded complaints from GDB feature class: 450976\n",
      "Sampled complaints to 10000 points for performance.\n",
      "Complaints CRS: EPSG:4326\n",
      "Sampled complaints to 10000 points for performance.\n",
      "Complaints CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# Load complaint points: prefer GDB feature class, fallback to CSV\n",
    "complaints_gdf = safe_read_gdb(GDB_PATH, FEATURECLASS_NAME)\n",
    "if complaints_gdf is not None:\n",
    "    print('Loaded complaints from GDB feature class:', len(complaints_gdf))\n",
    "    if complaints_gdf.crs and complaints_gdf.crs.to_epsg() != 4326:\n",
    "        complaints_gdf = complaints_gdf.to_crs(4326)\n",
    "else:\n",
    "    print('Falling back to CSV for complaints.')\n",
    "    df_2019 = pd.read_csv(COMPLAINTS_2019_CSV)\n",
    "    lat_col, lon_col = detect_coordinate_columns(df_2019)\n",
    "    if lat_col and lon_col:\n",
    "        complaints_gdf = try_build_points(df_2019, lat_col, lon_col)\n",
    "        print('Built point GeoDataFrame from CSV:', len(complaints_gdf))\n",
    "    else:\n",
    "        complaints_gdf = gpd.GeoDataFrame(columns=['geometry'], geometry=[])\n",
    "        print('No coordinate columns detected; complaints layer empty.')\n",
    "\n",
    "# Optionally sample to improve rendering performance (automatic)\n",
    "if len(complaints_gdf) > MAX_POINTS:\n",
    "    complaints_gdf = complaints_gdf.sample(MAX_POINTS, random_state=42)\n",
    "    print(f'Sampled complaints to {len(complaints_gdf)} points for performance.')\n",
    "\n",
    "print('Complaints CRS:', complaints_gdf.crs)\n",
    "\n",
    "# Sanitize complaint properties too (for choropleth & potential popups)\n",
    "complaints_gdf = sanitize_properties(complaints_gdf)\n",
    "\n",
    "# Keep only geometry to reduce payload size\n",
    "if 'geometry' in complaints_gdf.columns:\n",
    "    complaints_gdf = complaints_gdf[['geometry']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41e4531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No precinct column detected in complaints; choropleth skipped.\n"
     ]
    }
   ],
   "source": [
    "# Aggregate complaints per precinct for choropleth (attempt using common precinct columns)\n",
    "precinct_cols_candidates = [c for c in complaints_gdf.columns if 'precinct' in c.lower()]\n",
    "choropleth_df = None\n",
    "if precinct_cols_candidates:\n",
    "    precinct_col = precinct_cols_candidates[0]\n",
    "    # Normalize precinct ID to string for join\n",
    "    counts = complaints_gdf.groupby(precinct_col).size().reset_index(name='complaint_count')\n",
    "    # Attempt to find matching precinct key in precincts layer\n",
    "    precinct_key_candidates = [c for c in precincts_simplified.columns if 'precinct' in c.lower() or 'prec' in c.lower()]\n",
    "    if precinct_key_candidates:\n",
    "        precinct_key = precinct_key_candidates[0]\n",
    "        # Cast types for join\n",
    "        counts[precinct_col] = counts[precinct_col].astype(str)\n",
    "        precincts_simplified[precinct_key] = precincts_simplified[precinct_key].astype(str)\n",
    "        choropleth_df = precincts_simplified.merge(counts, left_on=precinct_key, right_on=precinct_col, how='left')\n",
    "        choropleth_df['complaint_count'].fillna(0, inplace=True)\n",
    "        # Keep minimal columns for rendering\n",
    "        choropleth_df = choropleth_df[['geometry', precinct_key, 'complaint_count']]\n",
    "        print('Choropleth join complete. Rows:', len(choropleth_df))\n",
    "    else:\n",
    "        print('Could not find precinct key in precincts layer; skipping choropleth.')\n",
    "else:\n",
    "    print('No precinct column detected in complaints; choropleth skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fc6a1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.map.LayerControl at 0x1c9b85cb380>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build interactive Folium map\n",
    "m = folium.Map(location=[NYC_LAT, NYC_LON], zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "def style_func_psa(_):\n",
    "    return {'color': '#1f77b4', 'weight': 1, 'fillOpacity': 0.05}\n",
    "def style_func_sectors(_):\n",
    "    return {'color': '#ff7f0e', 'weight': 1, 'fillOpacity': 0.05, 'dashArray': '4 4'}\n",
    "def style_func_precincts(_):\n",
    "    return {'color': '#2ca02c', 'weight': 1.2, 'fillOpacity': 0.04}\n",
    "\n",
    "folium.GeoJson(psa_simplified, name='PSA', style_function=style_func_psa,\n",
    "               tooltip=folium.GeoJsonTooltip(fields=[c for c in psa_simplified.columns if c.lower().startswith('psa')][:1] or None)).add_to(m)\n",
    "folium.GeoJson(sectors_simplified, name='Sectors', style_function=style_func_sectors).add_to(m)\n",
    "folium.GeoJson(precincts_simplified, name='Precincts', style_function=style_func_precincts).add_to(m)\n",
    "\n",
    "# Add complaint points using FastMarkerCluster for performance\n",
    "if not complaints_gdf.empty:\n",
    "    coords = [[round(pt.y, 5), round(pt.x, 5)] for pt in complaints_gdf.geometry if pt and not pt.is_empty]\n",
    "    if coords:\n",
    "        FastMarkerCluster(coords, name='Complaint Points').add_to(m)\n",
    "    else:\n",
    "        print('No valid point geometries found for markers.')\n",
    "else:\n",
    "    print('Complaint points layer empty; skipping markers.')\n",
    "\n",
    "# Choropleth layer if available\n",
    "if choropleth_df is not None:\n",
    "    precinct_key_candidates = [c for c in choropleth_df.columns if 'precinct' in c.lower() or 'prec' in c.lower()]\n",
    "    if precinct_key_candidates:\n",
    "        precinct_key = precinct_key_candidates[0]\n",
    "        folium.Choropleth(\n",
    "            geo_data=choropleth_df.__geo_interface__,\n",
    "            data=choropleth_df[[precinct_key, 'complaint_count']],\n",
    "            columns=[precinct_key, 'complaint_count'],\n",
    "            key_on=f'feature.properties.{precinct_key}',\n",
    "            fill_color='YlOrRd',\n",
    "            fill_opacity=0.6,\n",
    "            line_opacity=0.2,\n",
    "            nan_fill_color='white',\n",
    "            legend_name='Complaint Count',\n",
    "            name='Complaints Choropleth'\n",
    "        ).add_to(m)\n",
    "    else:\n",
    "        print('Precinct key missing for choropleth rendering.')\n",
    "\n",
    "folium.LayerControl(collapsed=False).add_to(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee83dc",
   "metadata": {},
   "source": [
    "## Performance & Next Steps\n",
    "- If rendering is slow: increase simplification tolerance or sample points.\n",
    "- Add temporal filters by extracting date columns and using widgets (e.g., ipywidgets).\n",
    "- Export map to HTML: `m.save('nyc_crime_map.html')`.\n",
    "- Enhance popups with offense description, time of day bins, or victim demographics.\n",
    "- Integrate advanced visualization (kepler.gl, deck.gl via pydeck) for 3D density surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca8e1866",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('NYC_optimized_crime_map.html') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
